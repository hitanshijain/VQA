## Project 1 Report

# Visual Question Answering using Machine Learning

## Hitanshi Jain

### Problem Statement/Applications

Visual Question Answering is a research area about building an AI system to answer questions presented in a natural language about an image. A VQA system takes an image and a free-form, open-ended, natural language question about the image as an input and produces a natural language answer as the output.
Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions.

VQA is directly applicable to a variety of applications of high societal impact that involve humans eliciting situationally-relevant information from visual data; where humans and machines must collaborate to extract information from pictures. Assistance to blind people is among the objectives of several VQA applications proposed in recent years. This is mainly due to the ability of automatic VQA to answer daily questions which may help visually impaired people to live without visual barriers. The adoption of a VQA approach in video surveillance scenarios may help operators to enhance the understanding of a
scene, thus helping them to take fair and faster decisions. One of the other most interesting applications of VQA is interacting with a robot (“Is my laptop in my bedroom upstairs?”). It can also be used for educational purposes and another application could be on social media or e-commerce sites.

In the most common form of Visual Question Answering (VQA), the computer is presented with an image and a textual question about this image. It must then determine the correct answer, typically a few words or a short phrase. Variants include binary (yes/no) and multiple-choice settings, in which candidate answers are proposed. A major distinction between VQA and other tasks in computer vision is that the question to be answered is not determined until run time. In traditional problems such as segmentation or object detection, the single question to be answered by an algorithm is predetermined and only the input image changes. In VQA, in contrast, the form that the question will take is unknown, as is the set of operations required to answer it. In this sense, it more closely reflects the challenge of general image understanding.

### Current Research

Visual Question Answering (VQA) is at present one of the most interesting joint applications of Artificial Intelligence (AI) to Computer Vision (CV) and Natural Language Processing (NLP). Its purpose is to achieve systems capable of answering different types of questions expressed in natural language and
regarding any image. To this aim, a VQA system relies on algorithms of different nature that jointly take as input an image and a natural language question about it and generate a natural language answer as output. Humans naturally succeed in this, except for special conditions, and AI aims at reproducing
this ability. The role of NLP in solving this multi-disciplinary problem is to understand the question, and of course to generate the answer according to the results obtained by CV.


